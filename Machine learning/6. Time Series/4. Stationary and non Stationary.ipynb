{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95bf364c",
   "metadata": {},
   "source": [
    "## Expalin stationary and non-stationaty time serie data with example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1781bb9",
   "metadata": {},
   "source": [
    "Stationarity and non-stationarity are concepts used in time series analysis to describe the behavior of a sequence of data points observed over time. Here's an explanation of these concepts with examples:\n",
    "\n",
    "- 1. `Stationary Time Series:`A stationary time series is one where the statistical properties of the data remain constant over time. This means that the mean, variance, and autocovariance structure of the series do not change with time. In simpler terms, the data points fluctuate around a constant mean and have a consistent pattern of variability. Stationary time series are easier to analyze and model because they exhibit predictable behavior.\n",
    "\n",
    "`Example`: A Gaussian white noise process is an example of a stationary time series. In this process, each observation is independently and identically distributed (iid) with a Gaussian (normal) distribution. The mean, variance, and autocovariance of the series remain constant over time. When plotted, a stationary time series appears to have random fluctuations around a constant mean.\n",
    "\n",
    "- 2. `Non-stationary Time Series:` A non-stationary time series is one where the statistical properties of the data change over time. The mean, variance, or autocovariance structure of the series may exhibit a trend, seasonality, or other patterns that evolve with time. Non-stationary time series often have changing means, trends, or irregular fluctuations, making them more challenging to analyze and predict.\n",
    "\n",
    "`Example`: A random walk is an example of a non-stationary time series. It is obtained by taking a cumulative sum of independent and identically distributed random variables. In a random walk, the mean value increases or decreases over time, leading to a changing mean and variance. When plotted, a non-stationary time series like a random walk shows a clear upward or downward trend.\n",
    "\n",
    "It's important to distinguish between weak sense stationarity and strict stationarity. Weak sense stationarity refers to a time series where the mean and autocovariance are approximately constant over time, allowing for small fluctuations. On the other hand, strict stationarity requires the exact constancy of all statistical properties of the series.\n",
    "\n",
    "Understanding whether a time series is stationary or non-stationary is crucial for selecting appropriate models and statistical techniques for analysis and forecasting. Various tests, such as the KPSS (Kwiatkowski-Phillips-Schmidt-Shin) test, can be performed to assess stationarity in a time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef857315",
   "metadata": {},
   "source": [
    "## How stationary is differ from Horizontal trends. Explain with Example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5988b74d",
   "metadata": {},
   "source": [
    "Stationarity refers to a property of a stochastic process where its statistical properties, such as mean and variance, remain constant over time. In the context of time series analysis, stationarity is an important assumption for many models and statistical techniques. However, not all time series are stationary, and they can exhibit different types of behavior. Two common types of nonstationary time series are trend stationary and difference stationary.\n",
    "\n",
    "Trend stationary process:\n",
    "A trend stationary process is a stochastic process from which an underlying trend, which can be a function of time, can be removed, resulting in a stationary process. The trend in a trend stationary process may not necessarily be linear. The mean of a trend stationary process may be growing or decreasing over time, but when a shock occurs, the process reverts back to the trend in the long run, meaning the effects of shocks are transitory.\n",
    "\n",
    "An example of a trend stationary process can be observed in economic time series data, such as the quarterly U.S. GDP measured from 1947 to 2005. This series exhibits an obvious upward trend over time. By incorporating the trend into the model and removing it, the residual series becomes a stationary stochastic process. The trend in this case is considered deterministic, and once estimated and removed, the remaining series behaves as a stationary process with a mean of zero [1].\n",
    "\n",
    "Difference stationary process:\n",
    "A difference stationary process, also known as a unit root process, requires differencing to be made stationary. Differencing involves taking the difference between consecutive observations in the time series. The order of differencing required is denoted by \"D,\" and the process is denoted as ΔD. By differencing the series D times, a stationary stochastic process is obtained. In a difference stationary process, the mean trend is stochastic, and the effects of shocks to the system are permanent. Unlike trend stationary processes, difference stationary processes do not revert to the trend in the long run.\n",
    "\n",
    "To illustrate, consider the Box-Jenkins modeling approach, where nonstationary time series are differenced until stationarity is achieved. The differenced series is represented as ΔDyt, where yt is the original nonstationary series. The differencing operator ΔD = (1−L)D is applied D times to the series. The lag operator polynomial ψ(L) is then used to model the differenced series, where εt represents the stationary residual term [1].\n",
    "\n",
    "In summary, the key difference between trend stationary and difference stationary processes lies in the nature of the mean trend and the behavior of the series after a shock. Trend stationary processes exhibit a deterministic mean trend and revert to the trend in the long run after a shock. Difference stationary processes have a stochastic mean trend and do not recover from shocks, leading to permanent effects on the mean of the series ["
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b189564f",
   "metadata": {},
   "source": [
    "## Importance of Stationary in the time Series Data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d587bd88",
   "metadata": {},
   "source": [
    "Stationarity is an important concept in time series analysis with significant implications for how data is perceived and predicted. Here are some reasons why stationarity is crucial in time series analysis:\n",
    "\n",
    "1. `Simplifies analysis`: Stationary time series exhibit consistent statistical properties over time, such as constant mean and variance. This simplifies the analysis process as many statistical techniques and models rely on the assumption of stationarity. Without stationarity, the properties of the time series may change over time, making it challenging to apply traditional analysis methods.\n",
    "\n",
    "2. `Enables accurate forecasting`: Stationary time series are more predictable compared to non-stationary series. Forecasting models often assume that the underlying data has a stable statistical structure. By ensuring stationarity, we can apply various forecasting techniques, such as autoregressive integrated moving average (ARIMA) models, which assume stationarity to make accurate predictions.\n",
    "\n",
    "3. `Facilitates statistical modeling`: Stationarity allows the use of statistical models that assume constant parameters and relationships over time. Models like ARIMA, exponential smoothing, and state space models are built on the assumption of stationarity. By ensuring stationarity, we can apply these models effectively and derive meaningful insights from the data.\n",
    "\n",
    "4. `Validates statistical tests`: Many statistical tests and procedures used in time series analysis assume stationarity, such as t-tests, correlation analysis, and regression models. Violating the stationarity assumption can lead to incorrect results and misleading conclusions. By verifying stationarity, we ensure the validity of these tests and the reliability of the statistical inferences.\n",
    "\n",
    "5. `Improves long-term stability`: Stationarity implies that the underlying process is not subject to significant structural changes over time. This stability is essential for making long-term predictions and decisions based on the time series data. Non-stationary series, on the other hand, may exhibit trends, seasonality, or other patterns that can lead to incorrect long-term projections.\n",
    "\n",
    "In summary, stationarity is vital in time series analysis because it simplifies analysis, enables accurate forecasting, facilitates statistical modeling, validates statistical tests, and improves long-term stability. By ensuring stationarity, we can apply appropriate techniques, models, and tests to gain meaningful insights from time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98d4dd4",
   "metadata": {},
   "source": [
    "## What are method to make a time series data into stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e205076c",
   "metadata": {},
   "source": [
    "To make a time series data stationary, there are several methods that can be employed. Here are some commonly used techniques:\n",
    "\n",
    "1. `Differencing`: One of the simplest methods is differencing, where the original time series is subtracted from a lagged version of itself. This helps in removing the trend or seasonality component from the data, making it stationary.\n",
    "\n",
    "2. `Logarithmic Transformation`: Taking the logarithm of the values can stabilize the variance of the time series. This is particularly useful when the data exhibits exponential growth or a changing variance over time.\n",
    "\n",
    "3. `Seasonal Adjustment`: If the time series data exhibits seasonality, seasonal adjustment methods can be used to remove the seasonal component. Techniques like seasonal decomposition of time series (e.g., using the X-12-ARIMA or STL decomposition) can help identify and remove the seasonal patterns, making the data stationary.\n",
    "\n",
    "4. `Detrending`: Detrending involves removing the trend component from the time series. This can be done by fitting a regression model to the data and subtracting the predicted trend from the original series. Detrending can help eliminate long-term trends and make the data stationary.\n",
    "\n",
    "5. `Box-Cox Transformation`: The Box-Cox transformation is a power transformation that can be applied to stabilize the variance and make the data more normally distributed. It is particularly useful when the data exhibits heteroscedasticity.\n",
    "\n",
    "6. `Weighted Moving Average`: Another approach is to apply a weighted moving average to the time series data. This involves assigning larger weights to more recent observations and smaller weights to older observations. By doing so, the effects of older observations diminish, and the data can become more stationary.\n",
    "\n",
    "It's important to note that the choice of method depends on the specific characteristics of the time series data and the underlying patterns it exhibits. It's recommended to analyze the data and apply different techniques to identify the most suitable method for achieving stationarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96036469",
   "metadata": {},
   "source": [
    "## How to identify a time series is statiuonary or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7613fec",
   "metadata": {},
   "source": [
    "To identify whether a time series is stationary or not, there are several approaches and statistical tests available. Here are some methods commonly used to check the stationarity of a time series:\n",
    "\n",
    "1. `Visual Inspection`: One way to check for stationarity is to visually examine the plot of the time series data over time. Look for any noticeable trends, seasonality, or irregular patterns. If the data appears to have a consistent mean, variance, and no apparent trend or seasonality, it suggests stationarity. However, visual inspection alone may not provide conclusive evidence.\n",
    "\n",
    "2. `Statistical Tests:`\n",
    "- a. Augmented Dickey-Fuller (ADF) Test: The ADF test is one of the most commonly used statistical tests for stationarity [2]. It determines whether a unit root is present in the autoregressive model of the time series. The null hypothesis assumes the presence of a unit root (non-stationarity), and if the p-value is below a certain significance level (e.g., 0.05), the null hypothesis can be rejected, indicating stationarity.\n",
    "\n",
    "- b. Kwiatkowski-Phillips-Schmidt-Shin (KPSS) Test: The KPSS test is another widely used statistical test to check for stationarity [2]. It tests the null hypothesis that the time series is stationary against the alternative hypothesis of a unit root (non-stationarity). If the p-value is above a chosen significance level, the null hypothesis can be accepted, indicating stationarity.\n",
    "\n",
    "These statistical tests provide more quantitative measures to assess stationarity and are commonly implemented in statistical software packages.\n",
    "\n",
    "`Summary Statistics`: Calculate summary statistics such as the mean, variance, and covariance over different time periods. If these statistics remain relatively constant or do not exhibit significant changes over time, it suggests stationarity.\n",
    "\n",
    "It's important to note that stationarity is a prerequisite for many time series models and analysis techniques. Transforming non-stationary data into stationary data is often necessary to apply such models effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efa7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782e41e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eca0101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172af9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
